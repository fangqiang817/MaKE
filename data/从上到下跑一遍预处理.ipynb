{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sentencepiece as spm\n",
    "import copy\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_set = pd.read_excel('/share_v1/Tianqiao/NLG/question_generation/equation2text/case_study/自己编的测试集.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def process_scene(scene):\n",
    "    scene = scene.replace(' ','')\n",
    "    map_scene = {}\n",
    "    edge_0, edge_1 = re.split(r'\\),|\\)，',scene)\n",
    "    ent0, ent1 = edge_0.split('(')\n",
    "    map_scene[ent0] = ent1\n",
    "    \n",
    "    ent2, ent3 = edge_1[:-1].split('(')\n",
    "    map_scene[ent2] = ent3\n",
    "    return map_scene\n",
    "def process_var(var):\n",
    "    map_var = {}\n",
    "    edge_0, edge_1 = re.split(r'\\),|\\)，',var)\n",
    "    ent0, ent1 = edge_0.split('(')\n",
    "    map_var[ent1] = ent0.replace(' ','')\n",
    "    ent2, ent3 = edge_1[:-1].split('(')\n",
    "    map_var[ent3] = ent2.replace(' ','')\n",
    "    return map_var\n",
    "def process_mr(mr, var):\n",
    "    splited_mr = mr.split(',')\n",
    "    mr_dict = {}\n",
    "    for one in splited_mr:\n",
    "        ent0, ent1 = one.split('[')\n",
    "        mr_dict[ent0] = ent1[:-1]\n",
    "    processed_var = process_var(var)\n",
    "    mr_dict['x_ent'] = processed_var['x']\n",
    "    mr_dict['y_ent'] = processed_var['y']\n",
    "    return mr_dict\n",
    "def fenge_B006(text):\n",
    "    a = re.split(r'(\\+|,|-|\\*|/|=|!=|>=|<=|>|<|\\(|\\)|\\[|\\]|\\\\|\\|\\b\\d+\\w*\\b|[\\u4E00-\\u9FA5]|\\②|\\①|\\③|\\④|\\㉖|\\:)', text)\n",
    "    return [x.strip() for x in a if x!='']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 移项，如果变量在等号右边，把它移到左边\n",
    "def transfer_var(equation):\n",
    "    splited_equ = fenge_B006(equation)\n",
    "    equ_index = splited_equ.index('=')\n",
    "    equ_right = splited_equ[equ_index+1:]\n",
    "    equ_left = splited_equ[:equ_index]\n",
    "    left_yubei = []\n",
    "    right_yubei = []\n",
    "    for idx, ele in enumerate(equ_left):\n",
    "        if ('x' not in ele) and ('y' not in ele) and (ele not in ['+','-','*','/']):\n",
    "            # 有数字\n",
    "            if idx==0:\n",
    "                right_yubei += ['-', ele]\n",
    "                equ_left = equ_left[1:]\n",
    "            else:\n",
    "                if equ_left[idx-1] == '-':\n",
    "                    right_yubei += ['+', ele]\n",
    "                    equ_left = equ_left[:idx-1] + equ_left[idx+1:]\n",
    "                elif equ_left[idx-1] == '+':\n",
    "                    right_yubei += ['-', ele]\n",
    "                    equ_left = equ_left[:idx-1] + equ_left[idx+1:]\n",
    "    \n",
    "    equ_right = equ_right + right_yubei\n",
    "    if (equation.find('x') > equation.find('=')) or (equation.find('y') > equation.find('=')):\n",
    "        # 先把全部right元素移到左边\n",
    "        for idx, ele in enumerate(equ_right):\n",
    "            if ('x' in ele) or ('y' in ele):\n",
    "                if idx ==0:\n",
    "                    left_yubei += ['-',ele]\n",
    "                    if len(equ_right) == 1:\n",
    "                        equ_right[0] = '0'\n",
    "                    else:\n",
    "                        equ_right = equ_right[2:]\n",
    "                else:\n",
    "                    if equ_right[idx-1] == '-':\n",
    "                        left_yubei += ['+',ele]\n",
    "                        equ_right = equ_right[:idx-1] + equ_right[idx+1:]\n",
    "                    elif equ_right[idx-1] == '+':\n",
    "                        left_yubei += ['-', ele]\n",
    "                        equ_right = equ_right[:idx-1] + equ_right[idx+1:]\n",
    "    else:\n",
    "        return fenge_B006(equation)\n",
    "    \n",
    "#     print(equ_left)\n",
    "#     print(left_yubei)\n",
    "#     print(equ_right)\n",
    "#     print(right_yubei)\n",
    "    equ_left = equ_left + left_yubei\n",
    "    #equ_right = equ_right + right_yubei\n",
    "    return equ_left + ['='] + equ_right"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "guanxi1_trans, guanxi2_trans = [], []\n",
    "for idx, row in train_set.iterrows():\n",
    "    guanxi1 = row['关系1']\n",
    "    guanxi2 = row['关系2']\n",
    "    guanxi1_trans.append(''.join(transfer_var(guanxi1)))\n",
    "    guanxi2_trans.append(''.join(transfer_var(guanxi2)))\n",
    "train_set['关系1_trans'] = guanxi1_trans\n",
    "train_set['关系2_trans'] = guanxi2_trans"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def x_fir_y_sec(equation):\n",
    "    equ_left = equation[:equation.find('=')]\n",
    "    equ_right = equation[equation.find('='):]\n",
    "    splited_left = fenge_B006(equation[:equation.find('=')])\n",
    "    if equ_left.find('x') > equ_left.find('y'):\n",
    "        # x的表示在y的后面，不合理\n",
    "        if len(splited_left) == 3:\n",
    "            splited_left = splited_left[-2:] + ['+']+[splited_left[0]]\n",
    "            if splited_left[0] == '+':\n",
    "                splited_left = splited_left[1:]\n",
    "        elif len(splited_left) == 4:\n",
    "            splited_left = splited_left[-2:] + splited_left[:2]\n",
    "            if splited_left[0] == '+':\n",
    "                splited_left = splited_left[1:]\n",
    "    return ''.join(splited_left) + equ_right"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_set['关系1_trans'] = train_set['关系1_trans'].map(lambda x: x_fir_y_sec(x))\n",
    "train_set['关系2_trans'] = train_set['关系2_trans'].map(lambda x: x_fir_y_sec(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def get_equation_mr(equation1, equation2):\n",
    "    equ1_left = equation1[:equation1.find('=')]\n",
    "    equ1_right = equation1[equation1.find('=')+1:]\n",
    "    splited_left_1 = fenge_B006(equ1_left)\n",
    "    splited_right_1 = fenge_B006(equ1_right)\n",
    "    one_mr = []\n",
    "    # 先处理第一个式子的左半部分\n",
    "    if len(splited_left_1) == 3:\n",
    "        # 处理x部分\n",
    "        if splited_left_1[0] =='x':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq1_x_index[{}]'.format(splited_left_1[0].replace('x','')))\n",
    "        # 处理中间的那个运算符\n",
    "        one_mr.append('eq1_left_sym2[{}]'.format(splited_left_1[1]))\n",
    "        # 处理y部分\n",
    "        if splited_left_1[2] =='y':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq1_y_index[{}]'.format(splited_left_1[2].replace('y','')))\n",
    "    elif len(splited_left_1) == 4:\n",
    "        # 有四个部分，看起来都要做填充\n",
    "        # 第一个部分的符号\n",
    "        one_mr.append('eq1_left_sym1[{}]'.format(splited_left_1[0]))\n",
    "        if splited_left_1[1] =='x':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq1_x_index[{}]'.format(splited_left_1[1].replace('x','')))\n",
    "        # 第二个部分的符号\n",
    "        one_mr.append('eq1_left_sym2[{}]'.format(splited_left_1[2]))\n",
    "        # 处理y部分\n",
    "        if splited_left_1[3] =='y':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq1_y_index[{}]'.format(splited_left_1[3].replace('y','')))\n",
    "    else:\n",
    "        raise 'wrong input equation1, check preprocessing'\n",
    "    \n",
    "    # 处理第一个式子的右半部分\n",
    "    if len(splited_right_1) == 1:\n",
    "        # 只有一个实数，应该大部分都是如此\n",
    "        one_mr.append('eq1_right_num1[{}]'.format(splited_right_1[0]))\n",
    "    elif len(splited_right_1) == 3:\n",
    "        # 有实数的计算存在，好吧，那就算一算吧\n",
    "        one_mr.append('eq1_right_num1[{}]'.format(splited_right_1[0]))\n",
    "        one_mr.append('eq1_right_sym[{}]'.format(splited_right_1[1]))\n",
    "        one_mr.append('eq1_right_num2[{}]'.format(splited_right_1[2]))\n",
    "    \n",
    "    \n",
    "    equ2_left = equation2[:equation2.find('=')]\n",
    "    equ2_right = equation2[equation2.find('=')+1:]\n",
    "    splited_left_2 = fenge_B006(equ2_left)\n",
    "    splited_right_2 = fenge_B006(equ2_right)\n",
    "    \n",
    "    # 先处理第二个式子的左半部分\n",
    "    if len(splited_left_2) == 3:\n",
    "        # 处理x部分\n",
    "        if splited_left_2[0] =='x':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq2_x_index[{}]'.format(splited_left_2[0].replace('x','')))\n",
    "        # 处理中间的那个运算符\n",
    "        one_mr.append('eq2_left_sym2[{}]'.format(splited_left_2[1]))\n",
    "        # 处理y部分\n",
    "        if splited_left_2[2] =='y':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq2_y_index[{}]'.format(splited_left_2[2].replace('y','')))\n",
    "    elif len(splited_left_2) == 4:\n",
    "        # 有四个部分，看起来都要做填充\n",
    "        # 第一个部分的符号\n",
    "        one_mr.append('eq2_left_sym1[{}]'.format(splited_left_2[0]))\n",
    "        if splited_left_2[1] =='x':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq2_x_index[{}]'.format(splited_left_2[1].replace('x','')))\n",
    "        # 第二个部分的符号\n",
    "        one_mr.append('eq2_left_sym2[{}]'.format(splited_left_2[2]))\n",
    "        # 处理y部分\n",
    "        if splited_left_2[3] =='y':\n",
    "            pass\n",
    "        else:\n",
    "            one_mr.append('eq2_y_index[{}]'.format(splited_left_2[3].replace('y','')))\n",
    "    else:\n",
    "        raise 'wrong input equation2, check preprocessing'\n",
    "    \n",
    "    # 处理第一个式子的右半部分\n",
    "    if len(splited_right_2) == 1:\n",
    "        # 只有一个实数，应该大部分都是如此\n",
    "        one_mr.append('eq2_right_num1[{}]'.format(splited_right_2[0]))\n",
    "    elif len(splited_right_2) == 3:\n",
    "        # 有实数的计算存在，好吧，那就算一算吧\n",
    "        one_mr.append('eq2_right_num1[{}]'.format(splited_right_2[0]))\n",
    "        one_mr.append('eq2_right_sym[{}]'.format(splited_right_2[1]))\n",
    "        one_mr.append('eq2_right_num2[{}]'.format(splited_right_2[2]))\n",
    "    return ','.join(one_mr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "new_mr = []\n",
    "for idx, row in train_set.iterrows():\n",
    "    equ1, equ2 = row['关系1_trans'], row['关系2_trans']\n",
    "    new_mr.append(get_equation_mr(equ1, equ2))\n",
    "train_set['mr'] = new_mr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def expand_mr(var, scene, now_mr, tou_info, jiao_info):\n",
    "    processed_var, processed_scene = process_var(var), process_scene(scene)\n",
    "    mr_dict = process_mr(now_mr, var)\n",
    "    mr_dict['scene_x'] = processed_scene[mr_dict['x_ent']]\n",
    "    mr_dict['scene_y'] = processed_scene[mr_dict['y_ent']]\n",
    "    mr_dict['head_info_entity'] = eval(tou_info)['entity']\n",
    "    mr_dict['head_info_unit'] = eval(tou_info)['unit']\n",
    "    mr_dict['jiao_info_unit'] = eval(jiao_info)['unit']\n",
    "    mr_dict['jiao_info_entity'] = eval(jiao_info)['entity']\n",
    "    return mr_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class Constants:  \n",
    "    def __init__(self):\n",
    "        self.BOS_WORD = '<s>'\n",
    "        self.EOS_WORD = '</s>'\n",
    "        self.PAD_WORD = '<pad>'\n",
    "        self.NONE_WORD = '<blank>'\n",
    "        self.UNK_WORD = '<unk>'\n",
    "        self.eq1_x_index_WORD = 'eq_one_x_index'\n",
    "        self.eq2_x_index_WORD = 'eq_two_x_index'\n",
    "        self.eq1_y_index_WORD = 'eq_one_y_index'\n",
    "        self.eq2_y_index_WORD = 'eq_two_y_index'\n",
    "        self.eq1_right_num1_WORD = 'eq_one_right_num_one'\n",
    "        self.eq2_right_num1_WORD = 'eq_two_right_num_one'\n",
    "        self.eq1_right_num2_WORD = 'eq_one_right_num_two'\n",
    "        self.eq2_right_num2_WORD = 'eq_two_right_num_two'\n",
    "        self.x_entity_WORD = 'x_entity'\n",
    "        self.y_entity_WORD = 'y_entity'\n",
    "        self.head_info_unit_WORD = 'head_info_unit'\n",
    "        self.jiao_info_unit_WORD = 'jiao_info_unit'\n",
    "        self.jiao_info_entity_WORD = 'jiao_info_entity'\n",
    "        self.head_info_entity_WORD = 'head_info_entity'\n",
    "        \n",
    "        self.PAD = 0\n",
    "        self.UNK = 1\n",
    "        self.BOS = 2\n",
    "        self.EOS = 3\n",
    "        self.eq1_x_index = 4\n",
    "        self.eq2_x_index = 5\n",
    "        self.eq1_y_index = 6\n",
    "        self.eq2_y_index = 7\n",
    "        self.eq1_right_num1 = 8\n",
    "        self.eq2_right_num1 = 9\n",
    "        self.eq1_right_num2 = 10\n",
    "        self.eq2_right_num2 = 11\n",
    "        self.x_entity = 12\n",
    "        self.y_entity = 13\n",
    "        self.head_info_unit = 14\n",
    "        self.jiao_info_unit = 15\n",
    "        self.jiao_info_entity =16\n",
    "        self.none=18\n",
    "        self.head_info_entity =17\n",
    "Constants = Constants()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "MR_FIELDS =['方程二右边数字一', '方程一右边数字一', 'x_entity','y_entity', 'head信息_entity',\n",
    "    '脚信息_entity', 'head信息_unit', '脚信息_unit', \n",
    "    '方程一y系数', '方程二y系数', '方程一x系数', '方程二x系数','方程一右边数字二','方程二右边数字二',\n",
    "    '方程一左运算符1','方程一左运算符2','方程一右运算符','方程二左运算符1','方程二左运算符2','方程二右运算符',\n",
    "           '场景_x','场景_y']\n",
    "MR_FIELDS = ['eq2_right_num1', 'eq1_right_num1','x_ent','y_ent','head_info_entity','jiao_info_entity',\n",
    "             'head_info_unit','jiao_info_unit', 'eq1_y_index', 'eq2_y_index', 'eq1_x_index', 'eq2_x_index', 'eq1_right_num2',\n",
    "              'eq2_right_num2', 'eq1_left_sym1', 'eq1_left_sym2', 'eq1_right_sym', 'eq2_left_sym1','eq2_left_sym2',\n",
    "            'eq2_right_sym','scene_x','scene_y']\n",
    "\n",
    "MR_KEYMAP = dict((key, idx) for idx, key in enumerate(MR_FIELDS))\n",
    "MR_KEY_NUM = len(MR_FIELDS)\n",
    "\n",
    "lex_fields = ['方程二右边数字一', '方程一右边数字一', 'x_entity', 'y_entity', 'head信息_entity', '脚信息_entity',\n",
    "              'head信息_unit','脚信息_unit',\n",
    "    '方程一y系数', '方程二y系数', '方程一x系数', '方程二x系数', '方程一右边数字二','方程二右边数字二']\n",
    "lex_fields = ['eq2_right_num1', 'eq1_right_num1','x_ent','y_ent','head_info_entity','jiao_info_entity',\n",
    "             'head_info_unit','jiao_info_unit', 'eq1_y_index', 'eq2_y_index', 'eq1_x_index', 'eq2_x_index', 'eq1_right_num2',\n",
    "              'eq2_right_num2']\n",
    "\n",
    "lex_tar = [Constants.eq2_right_num1_WORD, Constants.eq1_right_num1_WORD, Constants.x_entity_WORD, Constants.y_entity_WORD, Constants.head_info_entity_WORD, Constants.jiao_info_entity_WORD,\n",
    "    Constants.head_info_unit_WORD, Constants.jiao_info_unit_WORD,\n",
    "    Constants.eq1_y_index_WORD,Constants.eq2_y_index_WORD,\n",
    "    Constants.eq1_x_index_WORD, Constants.eq2_x_index_WORD, Constants.eq1_right_num2_WORD, Constants.eq2_right_num2_WORD]\n",
    "\n",
    "lex_keymap = dict((key, idx) for idx, key in enumerate(lex_fields))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "tou = list(train_set[\"头信息\"])\n",
    "jiao = list(train_set[\"脚信息\"])\n",
    "scene = list(train_set[\"scene\"])\n",
    "bian_liang = list(train_set[\"变量\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "for i in range(len(tou)):\n",
    "    tou[i] = tou[i].replace(\"\\xa0\",\"\")\n",
    "    jiao[i] = jiao[i].replace(\"\\xa0\",\"\")\n",
    "    scene[i] = scene[i].replace(\"\\xa0\",\"\")\n",
    "    bian_liang[i] = bian_liang[i].replace(\"\\xa0\",\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "train_set[\"头信息\"] = tou\n",
    "train_set[\"脚信息\"] = jiao\n",
    "train_set[\"scene\"] = scene\n",
    "train_set[\"变量\"] = bian_liang"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "seq2seq_train_mr = []\n",
    "for idx, row in train_set.iterrows():\n",
    "    seq2seq_train_mr.append(expand_mr(row['变量'], row['scene'], row['mr'], row['头信息'], row['脚信息']))\n",
    "train_set['seq2seq_mr'] = seq2seq_train_mr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "train_set.loc[51,\"scene\"] = \"大床房(住宿),标准间(住宿)\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "row"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "关系1                                                     x-y=12\n",
       "关系2                                                   2x-4y=60\n",
       "变量                                               大床房(x),标准间(y)\n",
       "scene                                         热巧克力(食物),柠檬水(食物)\n",
       "头信息                          {'entity':'','num':'','unit':'间'}\n",
       "脚信息                          {'entity':'','num':'','unit':'人'}\n",
       "new_type                                                 scene\n",
       "关系1_trans                                               x-y=12\n",
       "关系2_trans                                             2x-4y=60\n",
       "mr           eq1_left_sym2[-],eq1_right_num1[12],eq2_x_inde...\n",
       "Name: 51, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "class Constants:  \n",
    "    def __init__(self):\n",
    "        self.BOS_WORD = '<s>'\n",
    "        self.EOS_WORD = '</s>'\n",
    "        self.PAD_WORD = '<pad>'\n",
    "        self.NONE_WORD = '<blank>'\n",
    "        self.UNK_WORD = '<unk>'\n",
    "        self.eq1_x_index_WORD = 'eq_one_x_index'\n",
    "        self.eq2_x_index_WORD = 'eq_two_x_index'\n",
    "        self.eq1_y_index_WORD = 'eq_one_y_index'\n",
    "        self.eq2_y_index_WORD = 'eq_two_y_index'\n",
    "        self.eq1_right_num1_WORD = 'eq_one_right_num_one'\n",
    "        self.eq2_right_num1_WORD = 'eq_two_right_num_one'\n",
    "        self.eq1_right_num2_WORD = 'eq_one_right_num_two'\n",
    "        self.eq2_right_num2_WORD = 'eq_two_right_num_two'\n",
    "        self.x_entity_WORD = 'x_entity'\n",
    "        self.y_entity_WORD = 'y_entity'\n",
    "        self.head_info_unit_WORD = 'head_info_unit'\n",
    "        self.jiao_info_unit_WORD = 'jiao_info_unit'\n",
    "        self.jiao_info_entity_WORD = 'jiao_info_entity'\n",
    "        self.head_info_entity_WORD = 'head_info_entity'\n",
    "        \n",
    "        self.PAD = 0\n",
    "        self.UNK = 1\n",
    "        self.BOS = 2\n",
    "        self.EOS = 3\n",
    "        self.eq1_x_index = 4\n",
    "        self.eq2_x_index = 5\n",
    "        self.eq1_y_index = 6\n",
    "        self.eq2_y_index = 7\n",
    "        self.eq1_right_num1 = 8\n",
    "        self.eq2_right_num1 = 9\n",
    "        self.eq1_right_num2 = 10\n",
    "        self.eq2_right_num2 = 11\n",
    "        self.x_entity = 12\n",
    "        self.y_entity = 13\n",
    "        self.head_info_unit = 14\n",
    "        self.jiao_info_unit = 15\n",
    "        self.jiao_info_entity =16\n",
    "        self.none=18\n",
    "        self.head_info_entity =17\n",
    "Constants = Constants()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "all_keys = set()\n",
    "for idx, row in train_set.iterrows():\n",
    "    seq_mr = row['seq2seq_mr']\n",
    "    for one_key in list(seq_mr.keys()):\n",
    "        all_keys.add(one_key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "MR_FIELDS =['方程二右边数字一', '方程一右边数字一', 'x_entity','y_entity', 'head信息_entity',\n",
    "    '脚信息_entity', 'head信息_unit', '脚信息_unit', \n",
    "    '方程一y系数', '方程二y系数', '方程一x系数', '方程二x系数','方程一右边数字二','方程二右边数字二',\n",
    "    '方程一左运算符1','方程一左运算符2','方程一右运算符','方程二左运算符1','方程二左运算符2','方程二右运算符',\n",
    "           '场景_x','场景_y']\n",
    "MR_FIELDS = ['eq2_right_num1', 'eq1_right_num1','x_ent','y_ent','head_info_entity','jiao_info_entity',\n",
    "             'head_info_unit','jiao_info_unit', 'eq1_y_index', 'eq2_y_index', 'eq1_x_index', 'eq2_x_index', 'eq1_right_num2',\n",
    "              'eq2_right_num2', 'eq1_left_sym1', 'eq1_left_sym2', 'eq1_right_sym', 'eq2_left_sym1','eq2_left_sym2',\n",
    "            'eq2_right_sym','scene_x','scene_y']\n",
    "\n",
    "MR_KEYMAP = dict((key, idx) for idx, key in enumerate(MR_FIELDS))\n",
    "MR_KEY_NUM = len(MR_FIELDS)\n",
    "\n",
    "lex_fields = ['方程二右边数字一', '方程一右边数字一', 'x_entity', 'y_entity', 'head信息_entity', '脚信息_entity',\n",
    "              'head信息_unit','脚信息_unit',\n",
    "    '方程一y系数', '方程二y系数', '方程一x系数', '方程二x系数', '方程一右边数字二','方程二右边数字二']\n",
    "lex_fields = ['eq2_right_num1', 'eq1_right_num1','x_ent','y_ent','head_info_entity','jiao_info_entity',\n",
    "             'head_info_unit','jiao_info_unit', 'eq1_y_index', 'eq2_y_index', 'eq1_x_index', 'eq2_x_index', 'eq1_right_num2',\n",
    "              'eq2_right_num2']\n",
    "\n",
    "lex_tar = [Constants.eq2_right_num1_WORD, Constants.eq1_right_num1_WORD, Constants.x_entity_WORD, Constants.y_entity_WORD, Constants.head_info_entity_WORD, Constants.jiao_info_entity_WORD,\n",
    "    Constants.head_info_unit_WORD, Constants.jiao_info_unit_WORD,\n",
    "    Constants.eq1_y_index_WORD,Constants.eq2_y_index_WORD,\n",
    "    Constants.eq1_x_index_WORD, Constants.eq2_x_index_WORD, Constants.eq1_right_num2_WORD, Constants.eq2_right_num2_WORD]\n",
    "\n",
    "lex_keymap = dict((key, idx) for idx, key in enumerate(lex_fields))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('./processed_data/encoded_with_rev.model')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def tokenize_word(text, sp, lex_list=None):\n",
    "    words = []\n",
    "    if lex_list:\n",
    "        for word, tar in zip(lex_list, lex_tar):\n",
    "            if word is not None:\n",
    "                text = text.replace(word, tar)\n",
    "    for frag in sp.EncodeAsPieces(text):\n",
    "        words.append(frag)\n",
    "    return words\n",
    "def get_after_text(text, lex_list):\n",
    "    if lex_list:\n",
    "        for word, tar in zip(lex_list, lex_tar):\n",
    "            if word is not None:\n",
    "                text = text.replace(word, tar)\n",
    "    return text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "## 这个MR就是我们的seq了哈，要记住\n",
    "def process_jitu_mr_type(mr_dict):\n",
    "    mr_data = [Constants.NONE_WORD] * MR_KEY_NUM\n",
    "    \n",
    "    # hold lexicalized variants of key in lex_fields\n",
    "    lex = [None, None, None, None, None, None,None, None, None, None, None, None, None, None]\n",
    "    for idx, item in mr_dict.items():\n",
    "        key, raw_val = idx, item\n",
    "        if raw_val != '':\n",
    "            key_idx = MR_KEYMAP[key]\n",
    "            \n",
    "            if key in lex_keymap:\n",
    "                lex[lex_keymap[key]] = raw_val\n",
    "\n",
    "            if key in lex_fields:\n",
    "                if key == 'eq1_right_num1':\n",
    "                    if mr_dict[key] == '0':\n",
    "                        mr_data[key_idx] = '0'\n",
    "                    else:\n",
    "                        mr_data[key_idx] = lex_tar[lex_keymap[key]]\n",
    "                elif key == 'eq2_right_num1':\n",
    "                    if mr_dict[key] == '0':\n",
    "                        mr_data[key_idx] = '0'\n",
    "                    else:\n",
    "                        mr_data[key_idx] = lex_tar[lex_keymap[key]]\n",
    "                else:\n",
    "                    mr_data[key_idx] = lex_tar[lex_keymap[key]]\n",
    "            else:\n",
    "                mr_data[key_idx] = raw_val\n",
    "    return mr_data, lex"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "def read_insts_from_train_file(inst_file, sp, max_sen_len=None, mr_fields =MR_FIELDS,spec_field = lex_tar):\n",
    "    \"\"\"\n",
    "    max_sen_len: how many word in one sentence\n",
    "    spec_field: slor with lexicalized variants\n",
    "    :return: mr data, lex: [as top], target\n",
    "    \"\"\"\n",
    "    raw_data_src, raw_data_tgt = [],[]\n",
    "    lexicalization = []\n",
    "    trimmed_sent_count = 0\n",
    "    for idx, row in inst_file.iterrows():\n",
    "        mr, text = row['seq2seq_mr'], row['ref']\n",
    "        mr_data_src, this_lex = process_jitu_mr_type(mr)\n",
    "        this_text = tokenize_word(text, sp, this_lex)\n",
    "        raw_data_src.append(mr_data_src)\n",
    "        lexicalization.append(this_lex)\n",
    "        if max_sen_len is not None:\n",
    "            if len(this_text) > max_sen_len:\n",
    "                this_text = this_text[:max_sen_len]\n",
    "                trimmed_sent_count +=1\n",
    "        \n",
    "        if this_text:\n",
    "            raw_data_tgt += [this_text + [Constants.EOS_WORD]]\n",
    "        else:\n",
    "            raw_data_tgt += [None]\n",
    "    print('[Info] Get {} instances'.format(len(raw_data_tgt)))\n",
    "    \n",
    "    if trimmed_sent_count > 0:\n",
    "        print('[Warning] {} instances are trimmed to the max sentence length {}.'.format(trimmed_sent_count,max_sen_len))\n",
    "    return raw_data_src, lexicalization, raw_data_tgt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = torch.load('/share_v1/Tianqiao/NLG/question_generation_NAACL/processed_data/new_seq2seq_data.pt')\n",
    "word2idx = data['dict']['src']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data['train'].keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['src', 'tgt', 'lex'])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "len(data['train']['src']) + len(data['dev']['src']) + len(data['test']['src'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5447"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "5447/6053"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "biaozhu = pd.read_excel('检查标注.xlsx')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6041, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "tmp = []\n",
    "for i in range(len(train_set)):\n",
    "    tmp.append(\"\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "train_set[\"ref\"] = tmp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "train_seq2seq_src, train_seq2seq_lex, train_seq2seq_tgt = read_insts_from_train_file(train_set, sp)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Info] Get 60 instances\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "new_data = {\n",
    "    'dict':{\n",
    "        'src': word2idx,\n",
    "    },\n",
    "    'other_test':{\n",
    "        'src': train_seq2seq_src,\n",
    "        'tgt': train_seq2seq_tgt,\n",
    "        'lex': train_seq2seq_lex\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "torch.save(new_data,\"/share/fangqiang/naacl/clean_data/zijizao_diff.pt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atc_gpu",
   "language": "python",
   "name": "atc_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}